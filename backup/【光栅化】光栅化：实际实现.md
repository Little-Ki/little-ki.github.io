译自：https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/rasterization-practical-implementation.html

源代码：https://github.com/scratchapixel/scratchapixel-code/tree/main/rasterization-practical-implementation

# 改进光栅化算法

## 锯齿和抗锯齿
&emsp;&emsp;前面章节中介绍的技术奠定了光栅化算法的基础。并且我们已经以非常基本的方式实现了这些技术。 GPU 渲染管线和其他基于光栅化的渲染器使用相同的概念，但具有这些算法的高度优化版本。详细介绍用于加速算法的所有不同技巧超出了本介绍的范围。我们现在将简要回顾其中的一些内容，但计划将来专门针对该主题开设一课。

![jaggies](https://github.com/user-attachments/assets/1406ece2-6379-4e0c-bc5e-ac5b5181fc45)
> **图 1**：使用抗锯齿功能可以减少锯齿状边缘和像素伪影。

&emsp;&emsp;首先，让我们考虑 3D 渲染的一个基本问题。如果放大我们在上一章中渲染的三角形图像，您会注意到三角形的边缘是不平滑的（这种不规则性也会影响正方形边缘的棋盘图案）。图 1 中可见的阶梯状边缘称为**锯齿**。这些锯齿状或阶梯状的边缘不是人工添加的；它们是将三角形分解为像素的结果。通过光栅化，我们将连续表面（三角形）分解为离散元素（像素），这个过程在[渲染简介](https://www.scratchapixel.com/lessons/3d-basic-rendering/rendering-3d-scene-overview/computer-discrete-raster.html)中已经提到过。这就像用乐高积木表示连续的曲线或表面。想要不注意到砖块不可能的（图 2）。

![antialiasing1](https://github.com/user-attachments/assets/16b4c4cd-f777-4a15-9850-2e0edc569400)
> **图 2**：像素无法正确捕捉连续表面的形状。

&emsp;&emsp;渲染中的解决方案称为抗锯齿（AA）。我们为每个像素不仅仅只采样一个样本，而是将像素划分为子像素并对每个子像素执行覆盖测试（图 3）。虽然每个子像素仍然只是另一个“砖块”，但此方法以稍微更高的精度捕获对象的边缘。像素通常分为 N × N 子像素网格，其中 N 通常是 2 的幂（2、4、8 等），但从技术上讲它可以是大于或等于 1 的任何值（1、 2、3、4、5 等）。有多种方法可以解决锯齿问题，并且所描述的技术属于基于采样的抗锯齿方法。

![antialiasing3](https://github.com/user-attachments/assets/434aa93c-75c7-49bc-8f76-1a127bc8ee44)
> **图 3**：当仅使用一个采样时，三角形会丢失。然而，通过使用子像素，我们可以检测到该像素至少部分与三角形重叠。像素颜色等于子像素颜色的总和除以子像素数或采样数（在本例中为 16 个采样）。

&emsp;&emsp;最终像素颜色的计算方式为所有子像素颜色的总和除以子像素总数。例如，假设三角形是白色的。如果只有 2 个样本在 4 个样本中与三角形重叠，则最终像素颜色将等于 (0+0+1+1)/4=0.5。像素不会完全是白色或黑色，而是会逐渐过渡，从而减轻阶梯式像素伪影。这种技术称为抗锯齿。要充分理解抗锯齿，需要深入研究信号处理理论，这是一个庞大而复杂的主题。

![antialiasing2](https://github.com/user-attachments/assets/800f6a87-37c3-4841-9f8d-8eed23a1da9e)
> **图 4**：使用子像素有效消除锯齿。

![antialiasing4](https://github.com/user-attachments/assets/2740fb41-47f3-4c9e-9c21-0d08bf99200d)
> **图 5**：抗锯齿有助于平滑锯齿状边缘。

![antialiasing](https://github.com/user-attachments/assets/cba00a90-8455-4473-8fef-25b81bbb953d)
> **图 6**：每像素 1 个样本或 1 spp（上）与每像素 4 个样本（下）。

&emsp;&emsp;选择 2 的幂作为 N 是有好处的，因为当今大多数处理器都可以并行执行多条指令，并且并行指令的数量通常是 2 的幂。您可以在网上找到有关特定于 CPU 的 SSE 指令集等信息，同时 GPU 使用类似的概念。 SSE 是大多数现代 CPU 上提供的一项功能，通常可以同时（在一个周期内）执行 4 或 8 个浮点计算。这意味着，以一次浮点运算的成本，您实际上可以免费获得 3 或 7 次额外运算。理论上，这可以显着加快渲染时间 4 或 8 倍（尽管由于设置这些指令的少量开销，很难达到这样的性能水平）。例如，SSE 指令可以以计算一个像素为代价来渲染 2x2 子像素，从而几乎无需额外成本即可获得更平滑的边缘。

## 渲染像素块
&emsp;&emsp;另一种加速光栅化的技术涉及渲染像素块。我们不是测试块内的每个像素，而是首先检查块角处的像素。 GPU 算法可能使用 8x8 像素块。此方法是涉及图块的更复杂概念的一部分，我们不会在这里深入研究。如果 8x8 网格的所有四个角都覆盖了三角形，则块内的其余像素很可能也覆盖了三角形，如图 7 所示。

![rasterization-optimization](https://github.com/user-attachments/assets/facfbd78-df49-43ec-bd82-a1719720edd3)
> **图 7**：如果 8x8 像素网格的 4 个角与三角形重叠，则网格的所有剩余像素也会覆盖该三角形。

&emsp;&emsp;在这种情况下，无需测试其他像素，从而节省大量时间。这些像素可以简单地用三角形的颜色填充。如果顶点属性需要在像素块上进行插值，这个过程也会被简化。在块的角点计算出它们后，您只需在两个方向（水平和垂直）上线性插值它们即可。事实证明，这种优化对于屏幕上显示较大的三角形最为有效。较小的三角形不会从这种方法中受益太多。

## 优化edge函数
&emsp;&emsp;edge函数也可以被优化。让我们回顾一下它的实现：
```cpp
int orient2d(const Point2D& a, const Point2D& b, const Point2D& c)
{
    return (b.x - a.x) * (c.y - a.y) - (b.y - a.y) * (c.x - a.x);
}
```

&emsp;&emsp;请记住，此函数中的 a 和 b 表示三角形的顶点，c 表示像素坐标（在光栅空间中）。一个有趣的观察是，为三角形边界框内的每个像素调用此函数。当迭代多个像素时，只有 c 发生变化； a 和 b 保持不变。假设我们计算一次方程并得到结果 w0：
```
w0 = (b.x - a.x) * (c.y - a.y) - (b.y - a.y) * (c.x - a.x);
```

如果 c.x 增加步长 s（每像素增量），则 w0 的新值变为：
```
w0_new - w0 = -(b.y - a.y) * s;
```

&emsp;&emsp;由于 -(b.y - a.y) * s 对于特定三角形来说是常数（假定 s 是一致增量并且 a 和 b 是常数），因此我们可以计算一次并将其存储为 w0_step。这将计算简化为：
```
w0_new = w0 + w0_step;
```
&emsp;&emsp;此调整也可应用于 w1 和 w2，以及 c.y 中的增量。
&emsp;&emsp;最初，edge函数需要 2 次乘法和 5 次减法，但通过此优化，可以将其简化为简单的加法，尽管必须计算初始值。这项技术在网上被广泛讨论。虽然我们不会在本课程中使用它，但我们计划进一步探索它，并在未来专门讨论高级光栅化技术的课程中实现它。

## 定点坐标
![subpixel-precision](https://github.com/user-attachments/assets/4ced428f-3ac3-44c4-9e1d-97f202895d06)
> **图 8**：定点坐标。

&emsp;&emsp;为了结束本节，让我们简要讨论一下在光栅化阶段之前将顶点坐标从浮点格式转换为定点格式的技术。 “定点”是一个技术术语，本质上是整数表示。当顶点坐标从NDC转换为栅格空间时，它们也从浮点数转换为定点数。我们为什么要这样做？答案并不简单，但本质上，GPU 利用定点算术，因为通过逻辑位运算处理整数在计算上比处理浮点数或双精度数更容易、更快。这个解释相当笼统；从浮点到整数坐标的转变以及使用整数坐标实现光栅化涵盖了一个广泛而复杂的主题，在网上几乎没有记录，考虑到它在现代 GPU 功能中的核心作用，这是令人惊讶的。

&emsp;&emsp;此转换涉及将顶点坐标舍入到最接近的整数。然而，仅这样做可能会将顶点坐标与像素角对齐得太近，这对于静止图像来说是一个小问题，但会在动画中产生视觉伪影（顶点可能会逐帧与不同的像素对齐）。该解决方案涉及将数字转换为最小整数值，同时保留一些位来表示顶点的子像素位置（顶点位置的小数部分）。通常，GPU 为子像素精度分配 4 位。对于 32 位整数，1 位可能用于数字的符号，27 位用于顶点的整数位置，4 位用于顶点在像素内的小数位置。这种排列意味着顶点位置“对齐”到 16x16 子像素网格的最近角，如图 8 所示。尽管顶点仍然捕捉到网格，但此方法比将它们对齐到像素坐标的问题要少。此过程引入了其他挑战，包括整数溢出，这是因为整数表示的值范围比浮点数更窄。此外，集成抗锯齿功能会增加复杂性。彻底探索这个主题需要它自己的课程。

&emsp;&emsp;定点坐标加快了光栅化过程和edge函数计算。这种效率是将顶点坐标转换为整数的关键原因，该技术将在下一课中进一步讨论。

# 关于我们实施光栅化算法的注意事项
&emsp;&emsp;现在我们将简要回顾一下源代码章节中提供的代码，重点介绍其主要组件：

<details>
<summary>信息</summary>
&emsp;&emsp;此代码仅用于学习目的。这远非高效。简单的优化可以显着提高性能，但我们优先考虑的是清晰度而不是效率。我们的目标不是生成可用于生产的代码，而是促进对基本概念的理解。优化代码可能是一个很好的练习。
</details>

<details>
<summary>信息</summary>
&emsp;&emsp;程序呈现的对象存储在包含文件中。虽然对于小程序来说可以接受，但由于程序大小和编译时间可能会增加，因此在专业应用程序中通常会避免这种做法。然而，对于这个简单的演示，并且考虑到对象的大小适中，它不会造成任何问题。要更深入地了解如何在程序中表示 3D 对象几何形状，请参阅建模和几何部分中有关此主题的课程。该程序中使用的唯一信息是三角形顶点的位置（在世界空间中）及其纹理或 st 坐标。
</details>

* 我们按照[针孔相机模型](https://www.scratchapixel.com/lessons/3d-basic-rendering/3d-viewing-pinhole-camera/how-pinhole-camera-works-part-1.html)课程中概述的方法，使用computeScreenCooperatives 函数来确定屏幕坐标。这确保了我们的渲染输出与 Maya 的渲染相同，后者也采用基于物理的相机模型。
```cpp
float t, b, l, r; 

computeScreenCoordinates( 
    filmApertureWidth, filmApertureHeight, 
    imageWidth, imageHeight, 
    kOverscan, 
    nearClippingPlane, 
    focalLength, 
    t, b, l, r); 
```

* convertToRaster 函数将三角形顶点坐标从相机空间转换到光栅空间，类似于上一课中的computePixelCooperatives 函数。请记住，我们学习了一种将屏幕空间坐标转换为 NDC 空间（其中 GPU 领域中的坐标范围在 [-1,1] 之间）的方法。我们在这里应用相同的重新映射方法。与之前课程的一个重要区别是，投影点现在必须是 3D 点，其 x 和 y 坐标代表屏幕空间中的投影点，z 坐标反映顶点的相机空间 z 坐标。这个 z 坐标对于解决可见性问题至关重要，如第四章所述。
```cpp
convertToRaster(v0, worldToCamera, l, r, t, b, nearClippingPlane, imageWidth, imageHeight, v0Raster); 
convertToRaster(v1, worldToCamera, l, r, t, b, nearClippingPlane, imageWidth, imageHeight, v1Raster); 
convertToRaster(v2, worldToCamera, l, r, t, b, nearClippingPlane, imageWidth, imageHeight, v2Raster);
```

* 请记住，与三角形顶点关联的所有顶点属性也需要通过顶点的 z 坐标进行“预除”，以进行透视正确的插值。这通常发生在渲染三角形之前（紧邻像素遍历循环之前）。但是，在代码中，顶点 z 坐标设置为其倒数（以使用乘法而不是除法加快深度计算）。
```cpp
// 预先计算 z 的倒数
v0Raster.z = 1 / v0Raster.z, 
v1Raster.z = 1 / v1Raster.z, 
v2Raster.z = 1 / v2Raster.z; 

Vec2f st0 = st[stindices[i * 3]]; 
Vec2f st1 = st[stindices[i * 3 + 1]]; 
Vec2f st2 = st[stindices[i * 3 + 2]]; 

// 透视校正插值
st0 *= v0Raster.z, st1 *= v1Raster.z, st2 *= v2Raster.z;
```

* 该函数包含两个循环：一个迭代所有场景三角形的外循环和一个遍历与当前三角形重叠的包围框内的所有像素的内循环。值得注意的是，内循环中的一些变量是常量，因此可以预先计算，包括三角形顶点的 z 坐标逆，为覆盖三角形的每个像素线性插值（以及需要除以各自的 z 坐标的顶点属性） 。
```cpp
// 外循环：遍历所有三角形
for (uint32_t i = 0; i < ntris; ++i) {
    ...
    // Inner loop: Loop over pixels
    for (uint32_t y = y0; y <= y1; ++y) { 
        for (uint32_t x = x0; x <= x1; ++x) {
            ...
        }
    }
}
```

* 每个像素都使用edge函数技术进行测试。如果一个像素覆盖一个三角形，我们计算它的重心坐标，然后确定样本深度。通过深度缓冲区测试允许我们使用新的深度值更新缓冲区，并使用三角形颜色更新帧缓冲区。
```cpp
Vec3f pixelSample(x + 0.5, y + 0.5, 0); 
float w0 = edgeFunction(v1Raster, v2Raster, pixelSample); 
float w1 = edgeFunction(v2Raster, v0Raster, pixelSample); 
float w2 = edgeFunction(v0Raster, v1Raster, pixelSample); 
if (w0 >= 0 && w1 >= 0 && w2 >= 0) { 
    w0 /= area; 
    w1 /= area; 
    w2 /= area; 
    // 线性插值采样深度
    float oneOverZ = v0Raster.z * w0 + v1Raster.z * w1 + v2Raster.z * w2; 
    float z = 1 / oneOverZ; 
    // 通过深度测试?
    if (z < depthBuffer[y * imageWidth + x]) { 
        depthBuffer[y * imageWidth + x] = z;
        // Update frame buffer
        ...
    }
}
```

* **着色技术**：为了增强视觉趣味，我们采用了多种着色方法。该模型有一个顶点属性：st 或纹理坐标。这些坐标可以与称为面比率的简单着色技术相结合来创建棋盘图案。面比率是三角形法线（通过两个三角形边之间的叉积计算）和视线方向之间的点积。视线方向是从被着色的三角形上的点 P 到相机位置 E 的向量。在相机空间中，现在定义了所有点，相机位置简单地为 E=(0,0,0)，从而使视线方向-P，然后必须对其进行归一化。由于点积可能为负值，因此我们仅将其限制为正值。
```cpp
Vec3f n = (v1Cam - v0Cam).crossProduct(v2Cam - v0Cam); 
n.normalize(); 
Vec3f viewDirection = -pt; 
viewDirection.normalize(); 
// 面比率
float nDotView =  std::max(0.f, n.dotProduct(viewDirection));
```

* 该技术需要计算 P 的坐标，即像素覆盖的三角形上的点，就像任何其他顶点属性一样。我们获取相机空间中的顶点，将它们除以它们的 z 坐标，用重心坐标对它们进行插值，然后将结果乘以样本深度（也恰好是 P 的 z 坐标）：
```cpp
// 获取三角形在相机空间的坐标
Vec3f v0Cam, v1Cam, v2Cam; 
worldToCamera.multVecMatrix(v0, v0Cam); 
worldToCamera.multVecMatrix(v1, v1Cam); 
worldToCamera.multVecMatrix(v2, v2Cam); 

// 与任何其他顶点属性一样除以相应的 z 坐标并使用重心坐标进行插值
float px = (v0Cam.x/-v0Cam.z) * w0 + (v1Cam.x/-v1Cam.z) * w1 + (v2Cam.x/-v2Cam.z) * w2; 
float py = (v0Cam.y/-v0Cam.z) * w0 + (v1Cam.y/-v1Cam.z) * w1 + (v2Cam.y/-v2Cam.z) * w2; 
 
// P 在相机空间的坐标
Vec3f pt(px * z, py * z, -z);
```

* **帧缓冲区输出**：最后，帧缓冲区的内容保存在 PPM 文件中，展示渲染结果。
![cowresult](https://github.com/user-attachments/assets/d0ec8304-c06a-4c3a-b1c2-9d9e3f88fab6)

&emsp;&emsp;如图所示，渲染并不神秘。了解规则可以复制专业应用程序的输出。

![cowresult1](https://github.com/user-attachments/assets/cd0c1b1e-f730-486c-b8f0-2f80063bb98f)
![cowresult2](https://github.com/user-attachments/assets/2e30e567-b92c-40ef-9b15-db6ff750b2bf)

&emsp;&emsp;作为额外的见解，我们导出了每个图像像素重叠的三角形上的点的世界空间位置，在 3D 查看器中显示所有点。毫不奇怪，点仅出现在相机直接可见的物体部分上，这证实了深度缓冲技术的有效性。第二张图像提供了同一点集的特写（右）。

# 结论
&emsp;&emsp;光栅化的主要优点是它的简单性和速度，尽管它主要用于解决可见性问题。请记住，渲染涉及两个步骤：可见性和着色。该算法不提供着色解决方案。

&emsp;&emsp;本课程旨在深入介绍光栅化。如果您发现此内容具有启发性和教育意义，请考虑支持我们的工作。

# 练习
* 通过将像素分为4个子像素，在每个子像素的中间生成一个样本，对每个样本进行覆盖测试，将样本的颜色相加，除以4，并将像素颜色设置为结果来实现抗锯齿。该技术的实现可以在纹理课程中找到。
* 如果三角形法线与视线方向之间的点积低于某个阈值，则通过不渲染三角形来实现背面剔除。这利用了指向相反方向的向量具有负点积的原理。两个单位向量之间的点积是它们之间角度的余弦。将阈值表示为以度为单位的角度。
* 将 z 缓冲区的内容输出到 PPM 文件，将深度缓冲区值重新映射到范围 [0,255]。

# 引用
* "A Parallel Algorithm for Polygon Rasterization" by Juan Pineda, Siggraph 1988.
* "A Subdivision Algorithm for Computer Display of Curved Surfaces" by Edwin Earl Catmull, Thesis 1974.
* "Fundamentals of Texture Mapping and Image Warping" by Paul S. Heckbert, Thesis 1989.
* "The A-buffer, an Antialiased Hidden Surface Method", by Loren Carpenter, 1984.