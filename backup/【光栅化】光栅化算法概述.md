译自：https://www.scratchapixel.com/lessons/3d-basic-rendering/rasterization-practical-implementation/overview-rasterization-algorithm.html
# 前言
&emsp;&emsp;光栅化渲染技术无疑是渲染3D场景图像最常用的技术。然而，它可能是所有技术中理解最少、记录最少的技术，尤其是与光线追踪相比。

&emsp;&emsp;造成这种情况的原因是多方面的。首先，这是一种过去的技术。这并不是说该技术已经过时——恰恰相反。大多数用于通过该算法生成图像的技术都是在 20 世纪 60 年代和 20 世纪 80 年代初开发的。在计算机图形领域，这一时期类似于中世纪，开发这些技术的论文知识往往会丢失。光栅化也是 GPU 用于生成 3D 图形的技术。尽管自 GPU 首次发明以来，硬件技术已经发生了显着的发展，但自 20 世纪 80 年代初以来，它们实现的用于生成图像的基本技术并没有太大变化。硬件已经发展，但形成图像的底层管道却没有发展。事实上，这些技术是如此基础，并且如此深入地集成在硬件架构中，以至于它们经常被忽视（只有设计 GPU 的人才真正了解它们的作用，而这远非一项微不足道的任务。然而，设计 GPU 和理解光栅化算法的原理是两个不同的挑战；因此，解释后者应该不那么困难）

&emsp;&emsp;无论如何，我们认为解决这种情况紧迫且重要。通过本课程，我们的目标是成为第一个提供清晰完整的算法概述以及该技术的完整实际实现的资源。如果本课程提供了您一直在苦苦寻求的答案，请考虑捐款！这项工作是免费提供的，需要大量的努力工作。

&emsp;&emsp;注：本课程于 2010 年年中发布。
# 介绍
&emsp;&emsp;光栅化和光线追踪都旨在解决可见性或隐藏表面问题，尽管顺序不同。这些算法的共同点是它们基本使用几何技术来解决这个问题。在本课中，我们将简要描述光栅化算法的工作原理。理解原理非常简单，但实现它需要使用一系列技术，特别是几何领域的技术，本课程也对此进行了解释。

&emsp;&emsp;我们在本课程中开发的用于在实践中演示光栅化的程序非常重要，因为我们将在后续课程中再次使用它来实现光线追踪算法。在同一程序中实现这两种算法将使我们能够轻松比较两种渲染技术产生的输出（它们应该产生相同的结果，至少在应用着色之前）并评估它们的性能。这种比较将是更好地了解每种算法的优缺点的好方法。
# 光栅化算法

&emsp;&emsp;有多种光栅化算法，但为了开门见山，我们可以说所有这些不同的算法都基于同一个原则。或者说，这些算法是同一想法的变体。当我们在本课中讨论光栅化时，我们将参考这个想法或原则。

&emsp;&emsp;什么想法？在之前的课程中，我们讨论了光栅化和光线追踪之间的区别。我们还建议渲染过程本质上可以分解为两个主要任务：可见性和着色。光栅化，简单来说，主要是解决**可见性问题**的一种方法。可见性涉及确定 3D 对象的哪些部分对相机可见。这些对象的某些部分可能会被隐藏，因为它们要么位于相机的视野之外，要么被其他对象遮挡。

![raytracing-raster](https://github.com/user-attachments/assets/2ecf62e0-eb6a-4b31-9fe5-2a670a6398ba)
> 图 1：在光线追踪中，我们追踪穿过图像中每个像素中心的光线，然后测试该光线是否与场景中的任何几何体相交。如果找到相交，我们将像素的颜色设置为相交对象的颜色。由于一条射线可能与多个物体相交，因此我们需要跟踪最近的相交距离。

&emsp;&emsp;这个问题基本上可以通过两种方式解决。一种方法是追踪穿过图像中每个像素的光线，以确定相机与任何相交对象（如果有）之间的距离。通过该像素可见的对象是具有最小相交距离的对象（通常表示为 𝑡）。该技术用于光线追踪。在这种情况下，通过循环遍历图像中的所有像素、跟踪每个像素的光线并确定这些光线是否与场景中的任何对象相交来创建图像。本质上，该算法需要两个主循环。外循环迭代图像中的像素，内循环迭代场景中的对象：
```
for (each pixel in the image) { 
    Ray R = computeRayPassingThroughPixel(x,y); 
    float tClosest = INFINITY; 
    Triangle triangleClosest = NULL; 
    for (each triangle in the scene) { 
        float tHit; 
        if (intersect(R, object, tHit)) { 
             if (tHit < tClosest) { 
                 tClosest = tHit;
                 triangleClosest = triangle; 
             } 
        } 
    } 
    if (triangleClosest) { 
        imageAtPixel(x,y) = triangleColorAtHitPoint(triangleClosest, tClosest); 
    } 
}
```
&emsp;&emsp;在此示例中，假定对象由三角形（并且仅由三角形）组成。我们不迭代对象，而是将对象视为三角形的集合并迭代这些三角形。由于之前课程中已解释的原因，三角形通常用作光线追踪和光栅化中的基本渲染基元（GPU 需要对几何体进行三角测量）。

&emsp;&emsp;光线追踪代表了解决可见性问题的第一种方法。我们将该技术描述为**以图像为中心**，因为光线从相机射入场景（从图像开始），这与光栅化中使用的方法相反。

![raytracing-raster2](https://github.com/user-attachments/assets/cdd8d254-862f-4ef1-aa37-fe21c23b15fd)
> 图 2：光栅化可以大致分解为两个步骤。首先，我们使用透视投影将构成三角形的 3D 顶点投影到屏幕上。然后，我们循环图像中的所有像素并测试它们是否位于生成的 2D 三角形内。如果是，我们用三角形的颜色填充像素。

&emsp;&emsp;光栅化采用相反的方法来解决可见性问题。它将三角形“投影”到屏幕上，使用透视投影将 3D 表示转换为该三角形的 2D 表示。这种变换是通过将组成三角形的顶点投影到屏幕上（使用透视投影）来实现的。算法的后续步骤涉及采用一种技术来填充该 2D 三角形覆盖的所有图像像素。这两个步骤如图 2 所示。从技术上讲，它们执行起来很简单。投影步骤只需要进行透视划分以及将所得坐标从图像空间重新映射到光栅空间，这些过程我们已经在之前的课程中探讨过。确定图像中的哪些像素被生成的三角形覆盖同样简单，稍后将详细介绍。

&emsp;&emsp;该算法与光线追踪方法相比如何？首先，与首先迭代图像中的所有像素不同，在光栅化中，外部循环需要迭代场景中的所有三角形。然后，在内循环中，我们迭代图像中的所有像素，以确定当前像素是否落在当前三角形的“投影图像”内（如图 2 所示）。本质上，两种算法的内循环和外循环是相反的。
```
// 光栅化算法
for (each triangle in the scene) { 
    // STEP 1: Project vertices of the triangle using perspective projection
    Vec2f v0 = perspectiveProject(triangle[i].v0); 
    Vec2f v1 = perspectiveProject(triangle[i].v1); 
    Vec2f v2 = perspectiveProject(triangle[i].v2); 
    for (each pixel in the image) { 
        // STEP 2: Determine if this pixel is contained within the projected image of the triangle
        if (pixelContainedIn2DTriangle(v0, v1, v2, x, y)) { 
            image(x, y) = triangle[i].color; 
        } 
    } 
}
```

&emsp;&emsp;该算法是**以对象为中心**的，因为它从几何体开始，然后返回图像，而光线追踪方法则从图像开始，然后返回到场景。

&emsp;&emsp;这两种算法原则上都很简单，但在实现和解决所遇到的各种问题时，它们的复杂性略有不同。在光线追踪中，生成光线很简单，但找到光线与几何体的相交可能具有挑战性（取决于几何体类型）并且可能需要大量计算。不过，我们现在先把光线追踪放在一边。在光栅化算法中，我们需要将顶点投影到屏幕上，这既简单又快捷。我们将看到第二步，确定像素是否包含在三角形的二维表示中，有一个同样简单的几何解决方案。本质上，使用光栅化方法计算图像依赖于两种非常简单且快速的技术：透视过程和确定像素是否位于 2D 三角形内。光栅化体现了一种“优雅”算法。它采用的技术很容易解决；它们也很容易实施并产生可预测的结果。出于所有这些原因，该算法非常适合 GPU，并且是 GPU 用于生成 3D 对象图像的渲染技术（也可以轻松并行运行）。

总之：
* 将几何图形转换为三角形简化了过程。如果所有基元都转换为三角形基元，我们就可以开发快速高效的函数来将三角形投影到屏幕上并确定像素是否落在这些 2D 三角形内。
* 光栅化是**以对象为中心**的。我们将几何图形投影到屏幕上，并通过循环图像中的所有像素来确定它们的可见性。
* 它主要依赖于两种技术：将顶点投影到屏幕上并确定特定像素是否位于 2D 三角形内。
* GPU 上运行的渲染管线基于光栅化算法。

> “3D Z 缓冲线性插值多边形的快速渲染是最先进工作站的基础。一般来说，问题由两部分组成：1) 顶点的 3D 变换、投影和光照计算，以及2) 将多边形光栅化到帧缓冲区中。” （多边形光栅化的并行算法，Juan Pineda - 1988）

&emsp;&emsp;**光栅化**这个术语源于这样一个事实：多边形（在这种情况下是三角形）在某种程度上被分解为像素，众所周知，由像素组成的图像称为光栅图像。此过程在技术上称为**将三角形光栅化为图像或帧缓冲区**。

> “光栅化是确定哪些像素位于三角形内的过程，仅此而已。” （Michael Abrash）

&emsp;&emsp;到本课程的这一点，您应该了解如何使用光栅化方法生成 3D 场景的图像（由三角形组成）。到目前为止我们所描述的是该算法的最简单形式。它可以得到显着优化，此外，我们还没有解释当投影到屏幕上的两个三角形与图像中的相同像素重叠时会发生什么。当这种情况发生时，我们如何决定这两个（或更多）三角形中的哪一个对相机可见？我们现在就解答这两个问题。
<details>

<summary>信息</summary>
&emsp;&emsp;如果我的几何图形不是由三角形组成，会发生什么情况？我还可以使用光栅化算法吗？该问题最简单的解决方案是对几何体进行三角测量。现代 GPU 仅渲染三角形（以及线和点），因此无论如何您都需要对几何体进行三角测量。渲染 3D 几何体引入了一系列问题，使用三角形可以更轻松地解决这些问题。随着我们学习本课程的进展，您将会明白其中的原因。
</details>

# 优化过程：利用 2D 三角形的包围盒
![raytracing-raster3](https://github.com/user-attachments/assets/6b84f9ab-003f-4ed9-824a-cb28a9f28988)
> 图 3：为避免迭代图像中的所有像素，我们可以迭代 2D 三角形包围盒中包含的所有像素。

&emsp;&emsp;到目前为止，我们讨论的光栅化算法的简单实现的问题是，它需要在内循环中迭代图像中的所有像素，即使这些像素中只有一小部分可能被三角形包围（如图 3 所示）。当然，这取决于屏幕上三角形的大小。但考虑到我们的目标不仅仅是渲染一个三角形，而是渲染一个由数百到数百万个三角形组成的对象，在典型的生产环境中，这些三角形不太可能占据图像的很大一部分。

![raytracing-raster4](https://github.com/user-attachments/assets/eaf44f7c-b796-4f6f-9eb1-84ad5c4fde2f)
> 图 4：计算出三角形周围的包围盒后，我们可以循环遍历包围盒内的所有像素并测试它们是否与 2D 三角形重叠。

&emsp;&emsp;有多种方法可以减少测试的像素数量，但最常见的是计算投影三角形的 2D 包围盒并迭代该 2D 包围盒内的像素而不是整个图像。虽然某些像素可能仍然落在三角形之外，但这种方法可以显着提高算法的平均性能，如图 3 所示。

&emsp;&emsp;计算三角形的 2D 包围盒很简单。我们需要确定三角形顶点在光栅空间中的最小和最大 x 和 y 坐标。下面的伪代码说明了这个过程：
```
// 将当前三角形的顶点转换为光栅区域
Vec2f bbmin = INFINITY, bbmax = -INFINITY;
Vec2f vproj[3];
for (int i = 0; i < 3; ++i) {
    vproj[i] = projectAndConvertToNDC(triangle[i].v[i]);
    // Coordinates are in raster space but still floats, not integers
    vproj[i].x *= imageWidth;
    vproj[i].y *= imageHeight;
    if (vproj[i].x < bbmin.x) bbmin.x = vproj[i].x;
    if (vproj[i].y < bbmin.y) bbmin.y = vproj[i].y;
    if (vproj[i].x > bbmax.x) bbmax.x = vproj[i].x;
    if (vproj[i].y > bbmax.y) bbmax.y = vproj[i].y;
}
```
&emsp;&emsp;计算出三角形的 2D 边界框（在光栅空间中）后，我们只需要迭代该框定义的像素即可。然而，重要的是要注意光栅坐标（在我们的代码中定义为浮点数）如何转换为整数。值得注意的是，一两个顶点可能会投影到画布边界之外，这意味着它们的光栅坐标可能小于 0 或超过图像大小。我们通过将 x 坐标的像素坐标限制在 [0, 图像宽度 - 1] 范围内，将 y 坐标限制在 [0, 图像高度 - 1] 范围内来解决此问题。

&emsp;&emsp;此外，我们必须将边界框的最小和最大坐标舍入为最接近的整数值（这种方法在循环中迭代像素时非常有效，因为我们将变量初始化为 xmin 或 ymin，并在变量 x 或 y 超过最大值时退出循环）。所有这些调整都应在循环中使用边界框的坐标之前进行。这是伪代码：
```
...
uint xmin = std::max(0, std::min(imageWidth - 1, std::floor(bbmin.x)));
uint ymin = std::max(0, std::min(imageHeight - 1, std::floor(bbmin.y)));
uint xmax = std::max(0, std::min(imageWidth - 1, std::floor(bbmax.x)));
uint ymax = std::max(0, std::min(imageHeight - 1, std::floor(bbmax.y)));
for (y = ymin; y <= ymax; ++y) {
    for (x = xmin; x <= xmax; ++x) {
        // Check if the current pixel lies within the triangle
        if (pixelContainedIn2DTriangle(v0, v1, v2, x, y)) {
            image(x,y) = triangle[i].color;
        }
    }
}
```

<details>
<summary>信息</summary>
&emsp;&emsp;请注意，在生产环境中，光栅化器使用的优化方法比循环包含三角形的包围盒内的像素更有效。如前所述，许多像素不与三角形重叠，并且测试这些像素样本的重叠效率很低。这些更优化的方法超出了本课程的范围。
</details>

<details>
<summary>信息</summary>
&emsp;&emsp;如果您研究过该算法或 GPU 如何渲染图像，您可能听说过或读到过投影顶点的坐标有时会从浮点数转换为定点数（换句话说，整数）。这种转换的基本原理是，对定点数执行乘法、除法、加法等基本运算可以非常快速地执行（与对浮点数执行相同运算所需的时间相比）。虽然这种情况在过去很常见，并且 GPU 仍然被设计为在渲染管道的光栅化阶段处理整数，但现代 CPU 通常包含 FPU（浮点单元）。因此，如果您的程序在 CPU 上运行，那么使用定点数可能几乎没有任何好处（事实上，它甚至可能运行得更慢）。
</details>

# 了解图像缓冲区和帧缓冲区
&emsp;&emsp;我们的目标是生成场景图像。我们有两种方法来可视化程序的结果：要么直接在屏幕上显示渲染的图像，要么将图像保存到磁盘以便稍后使用 Photoshop 等程序查看。然而，在这两种情况下，我们都需要一种方法来存储正在渲染的图像。为此，我们利用计算机图形学中所谓的图像或帧缓冲区。这只是与图像大小匹配的二维颜色数组。在渲染过程开始之前，创建帧缓冲区，并且所有像素最初设置为黑色。在渲染期间，当三角形被光栅化时，如果给定像素与三角形重叠，则该三角形的颜色将存储在相应像素位置的帧缓冲区中。一旦所有三角形都被光栅化，帧缓冲区将包含场景的完整图像。最后一步是在屏幕上显示缓冲区的内容或将其保存到文件中。在本课中，我们将选择后者。

<details>
<summary>信息</summary>
&emsp;&emsp;不幸的是，目前还没有跨平台的解决方案来直接在屏幕上显示图像，这是令人遗憾的。因此，更实际的做法是将图像内容保存到文件中，并使用跨平台应用程序（例如 Photoshop 或其他图像编辑工具）来查看图像。你用来查看图像的软件自然必须支持图像保存的格式。在本课程中，我们将使用简单的 PPM 图像文件格式。
</details>

# 使用深度缓冲区解决重叠：处理每个像素的多个三角形
&emsp;&emsp;请记住，光栅化算法的主要目标是解决可见性问题。为了准确显示 3D 对象，识别哪些表面可见至关重要。在计算机图形学的早期，有两种流行的方法来解决“隐藏表面”问题（可见性问题的另一个术语）：Newell 算法和 z 缓冲区。我们仅在历史背景下提及 Newell 算法，本课程不会介绍它，因为它已不再使用。我们的重点将仅放在 z 缓冲区方法上，该方法仍然是 GPU 技术中的标准方法。

![raytracing-raster5](https://github.com/user-attachments/assets/cb9770cd-9ee5-4b64-88c7-a7bb40d29193)
> 图 5：当一个像素与两个三角形重叠时，像素颜色将设置为更靠近相机的三角形的颜色。

&emsp;&emsp;然而，为了操作基本光栅化器，我们必须考虑到图像中的同一像素可能有多个三角形（如图 5 所示）。那么，我们如何确定哪个三角形是可见的呢？解决方案很简单：使用 **z 缓冲区**，也称为**深度缓冲区**，您可能遇到过这个术语。 z 缓冲区本质上是另一个二维数组，与图像的尺寸相匹配。与颜色数组不同，它由浮点数组成。在渲染开始之前，该数组中的每个像素都被初始化为一个非常大的数字。当像素与三角形重叠时，我们还会检查该像素位置的 z 缓冲区中的值。该数组记录了每个像素从相机到最近的重叠三角形的距离。由于该初始值设置为无穷大（或任何显着较大的数字），因此首次检测到的像素 X 与三角形 T1 的重叠无疑将比 z 缓冲区中的值更接近。然后我们用到 T1 的距离更新该像素的值。如果相同的像素 X 后来与另一个三角形 T2 重叠，我们会将这个新三角形到相机的距离与 z 缓冲区的存储值（现在反映到 T1 的距离）进行比较。如果T2更近，它会遮挡T1；否则，T1 仍然是该像素最近遇到的三角形。因此，我们要么用 T2 的距离更新 z 缓冲区，要么维持 T1 的距离（如果它仍然是最接近的）。**因此，z 缓冲区记录了场景中每个像素的最近对象的距离**（尽管我们将在本课后面深入研究“距离”的细节）。在图 5 中，红色三角形在三维空间中位于绿色三角形后面。如果我们在绿色三角形之前渲染红色，则对于覆盖两者的任何像素，我们首先设置，然后使用到红色三角形和随后的绿色三角形的距离更新 z 缓冲区。

&emsp;&emsp您可能想知道我们如何确定相机到三角形的距离。让我们首先用伪代码检查该算法的实现，稍后我们将重新讨论这个问题（现在，我们假设函数 PixelContainedIn2DTriangle 为我们计算这个距离）：
```
// z 缓冲区只是浮点数的二维数组
float buffer = new float[imageWidth * imageHeight]; 
// 将每个像素的距离初始化为一个相当大的数字
for (uint32_t i = 0; i < imageWidth * imageHeight; ++i) 
    buffer[i] = INFINITY;
 
for (each triangle in the scene) { 
    // 投影顶点
    ... 
    // 计算投影三角形的包围盒
    ... 
    for (y = ymin; y <= ymax; ++y) { 
        for (x = xmin; x <= xmax; ++x) { 
            // Check if the current pixel is within the triangle
            float z;  // Distance from the camera to the triangle 
            if (pixelContainedIn2DTriangle(v0, v1, v2, x, y, &z)) { 
                // If the distance to that triangle is shorter than what's stored in the
                // z-buffer, update the z-buffer and the image at pixel location (x,y)
                // with the color of that triangle
                if (z < zbuffer(x, y)) { 
                    zbuffer(x, y) = z; 
                    image(x, y) = triangle[i].color; 
                } 
            } 
        } 
    } 
}
```

# 展望未来：光栅化的进一步探索
&emsp;&emsp;这只是该算法的非常高级的概述（如图 6 所示），但它应该可以让您很好地了解程序中生成图像所需的组件。我们将需要：
* 一个图像缓冲区（二维颜色数组）
* 一个深度缓冲区（二维浮点数数组）
* 三角形（构成场景的几何体）
* 将三角形的顶点投影到画布上的函数
* 光栅化投影三角形的函数
* 将图像缓冲区的内容保存到磁盘的一些代码。

![rasterization-schema](https://github.com/user-attachments/assets/764838f2-8cd4-42c8-96f3-590854ed7673)
> 图 6：光栅化算法的示意图。

&emsp;&emsp;在下一章中，我们将探讨如何将坐标从相机转换为光栅空间。尽管该方法与我们在上一课中学习和介绍的方法相同，但我们将在此过程中介绍一些额外的技巧。在第三章中，我们将学习如何光栅化三角形。第四章将详细介绍 z 缓冲区算法的功能。像往常一样，我们将以一个实际例子来结束本课。